{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1uMpnEGKIgD7ojUET8RkA36ewiBFcnnDN",
      "authorship_tag": "ABX9TyNgb7dO0BI27E8EILy8e4jW"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# *Game of Thrones* Sentiment Analysis"
      ],
      "metadata": {
        "id": "ca--nJV7Tt_f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal of this project is to determine the sentiment towards the final season of HBO's hit series *Game of Thrones*. To do this, we will use tweets during the weeks that the final season aired. Later, we will investigate how sentiment changed episode to episode.\n",
        "\n",
        "In this notebook we will be performing the sentiment analysis."
      ],
      "metadata": {
        "id": "HFj5oCPsTza9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Pq6IHR70Bmd"
      },
      "outputs": [],
      "source": [
        "# Import all the necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "nltk.download('twitter_samples') # dataset used to train the model\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('punkt')\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords, twitter_samples\n",
        "from nltk.tag import pos_tag\n",
        "from nltk.tokenize import word_tokenize, TweetTokenizer\n",
        "from nltk import classify, NaiveBayesClassifier\n",
        "import re, string\n",
        "from wordcloud import WordCloud,STOPWORDS"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the file with tweets\n",
        "got = pd.read_csv('/content/drive/MyDrive/gotTwitter.csv')"
      ],
      "metadata": {
        "id": "Z1ZeQt9_0dKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After importing the dataset, we will take a look at the columns that are of interest to us, the 'created_at' and 'text' columns. The 'created_at' column will help us see how sentiment changed over time and for each episode. The 'text' column contains the actual tweet and will be used to determine the sentiment. "
      ],
      "metadata": {
        "id": "_sYvpu9YWOwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gotsa = got[['created_at', 'text']]\n",
        "gotsa.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "djgs8unP3QMc",
        "outputId": "9ab600b0-96b2-4109-919a-18e429fc31fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            created_at                                               text\n",
              "0  2019-04-17 07:34:18  üëç on @YouTube: GAME OF THRONES 8x01 Breakdown!...\n",
              "1  2019-04-16 03:34:16  üëç on @YouTube: Ups and Downs From Game Of Thro...\n",
              "2  2019-04-16 03:06:08  Liked on YouTube: Ups and Downs From Game Of T...\n",
              "3  2019-04-17 07:07:38  Liked on YouTube: GAME OF THRONES 8x01 Breakdo...\n",
              "4  2019-04-17 07:34:09  @MrLegenDarius unpopular opinion: game of thro..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7c570879-d0df-4dc9-8660-f076380b61ec\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-04-17 07:34:18</td>\n",
              "      <td>üëç on @YouTube: GAME OF THRONES 8x01 Breakdown!...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019-04-16 03:34:16</td>\n",
              "      <td>üëç on @YouTube: Ups and Downs From Game Of Thro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-04-16 03:06:08</td>\n",
              "      <td>Liked on YouTube: Ups and Downs From Game Of T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019-04-17 07:07:38</td>\n",
              "      <td>Liked on YouTube: GAME OF THRONES 8x01 Breakdo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-04-17 07:34:09</td>\n",
              "      <td>@MrLegenDarius unpopular opinion: game of thro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c570879-d0df-4dc9-8660-f076380b61ec')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7c570879-d0df-4dc9-8660-f076380b61ec button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7c570879-d0df-4dc9-8660-f076380b61ec');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up the Sentiment Classifier"
      ],
      "metadata": {
        "id": "6VcH0WV2Ws7I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use twitter samples from the NLTK library to set up our sentiment analysis classifier. First we will set up our stop words to get rid of, and then we will tokenize the positive and negative tweets from the twitter samples, as we aren't interested in neutral sentiment."
      ],
      "metadata": {
        "id": "gZ4zzypKXWBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = stopwords.words('english')\n",
        "\n",
        "positive_tokens = twitter_samples.tokenized('positive_tweets.json')\n",
        "negative_tokens = twitter_samples.tokenized('negative_tweets.json')"
      ],
      "metadata": {
        "id": "XMgvh1hq5PEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we will clean the tweet tokens by removing hyperlinks, twitter handles, and punctuation. We will also normalize the tokens by using a lemmatizer. We do this for both the positive and negative tweets."
      ],
      "metadata": {
        "id": "iGDjJKohYPZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "positive_cleaned_tokens = []\n",
        "for i in range(len(positive_tokens)):\n",
        "  row_token = []\n",
        "  for token, tag in pos_tag(positive_tokens[i]):\n",
        "    token = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+#]|[!*\\(\\),]|'\\\n",
        "                    '(?:%[0-9a-fA-F][0-9a-fA-F]))+','', token) # remove any hyperlinks\n",
        "    token = re.sub('(@[A-Za-z0-9_]+)','', token) # remove any twitter handles\n",
        "    if tag.startswith('NN'): # assigning nouns\n",
        "      pos = 'n'\n",
        "    elif tag.startswith('VB'): # assigning verbs\n",
        "      pos = 'v'\n",
        "    else: # assigning adjectives\n",
        "      pos = 'a'\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    token = lemmatizer.lemmatize(token, pos) # lemmatize the token\n",
        "    if len(token) > 0 and token not in string.punctuation and token.lower() not in stop_words:\n",
        "      row_token.append(token.lower()) # save the token to the row (tweet)\n",
        "  positive_cleaned_tokens.append(row_token) # save the row (tweet) to the list of cleaned tweets"
      ],
      "metadata": {
        "id": "cFJE5MNMKGxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "negative_cleaned_tokens = []\n",
        "for i in range(len(negative_tokens)):\n",
        "  row_token = []\n",
        "  for token, tag in pos_tag(negative_tokens[i]):\n",
        "    token = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+#]|[!*\\(\\),]|'\\\n",
        "                    '(?:%[0-9a-fA-F][0-9a-fA-F]))+','', token) # remove any hyperlinks\n",
        "    token = re.sub('(@[A-Za-z0-9_]+)','', token) # remove any twitter handles\n",
        "    if tag.startswith('NN'): # assigning nouns\n",
        "      pos = 'n'\n",
        "    elif tag.startswith('VB'): # assigning verbs\n",
        "      pos = 'v'\n",
        "    else: # assigning adjectives\n",
        "      pos = 'a'\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    token = lemmatizer.lemmatize(token, pos) # lemmatize the token\n",
        "    if len(token) > 0 and token not in string.punctuation and token.lower() not in stop_words:\n",
        "      row_token.append(token.lower()) # save the token to the row (tweet)\n",
        "  negative_cleaned_tokens.append(row_token) # save the row (tweet) to the list of cleaned tweets"
      ],
      "metadata": {
        "id": "smaCAR1zMEL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After cleaning these tweets, we will create a function to put the words of the tweets into a dictionary so that it can be properly input into the Naives Bayes classifier."
      ],
      "metadata": {
        "id": "i-MMBqd2e3Ya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the function to put the tweet tokens into a dictionary\n",
        "def get_tweets_for_model(cleaned_tokens_list):\n",
        "  for tweet_tokens in cleaned_tokens_list:\n",
        "    yield dict([token, True] for token in tweet_tokens)"
      ],
      "metadata": {
        "id": "wVxjtFNsDEwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the function on both datasets\n",
        "positive_tokens_for_model = get_tweets_for_model(positive_cleaned_tokens)\n",
        "negative_tokens_for_model = get_tweets_for_model(negative_cleaned_tokens)"
      ],
      "metadata": {
        "id": "j6D_D_xsGLm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the datasets are in dictionaries, we will add a classifier to each tweet to denote if it has a positive or negative sentiment. Then we will combine the datasets into one and then create random training and testing datasets for the model."
      ],
      "metadata": {
        "id": "vG1t2B0bheOz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "positive_dataset = [(tweet_dict, \"Positive\")\n",
        "                     for tweet_dict in positive_tokens_for_model]\n",
        "\n",
        "negative_dataset = [(tweet_dict, \"Negative\")\n",
        "                     for tweet_dict in negative_tokens_for_model]\n",
        "\n",
        "dataset = positive_dataset + negative_dataset\n",
        "\n",
        "train_data, test_data = train_test_split(dataset, test_size=0.3, random_state=10)"
      ],
      "metadata": {
        "id": "MTHfO0HxGX-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we train the classifier and then test it."
      ],
      "metadata": {
        "id": "hfJCpgafh72r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = NaiveBayesClassifier.train(train_data)\n",
        "\n",
        "print(\"Accuracy is:\", classify.accuracy(classifier, test_data))\n",
        "\n",
        "print(classifier.show_most_informative_features(10))"
      ],
      "metadata": {
        "id": "6cSIXja7GwhG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d4b6482-960d-46bb-b5cf-ee014aac9bdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is: 0.9966666666666667\n",
            "Most Informative Features\n",
            "                      :( = True           Negati : Positi =   2032.2 : 1.0\n",
            "                      :) = True           Positi : Negati =   1007.5 : 1.0\n",
            "                follower = True           Positi : Negati =     39.9 : 1.0\n",
            "                     sad = True           Negati : Positi =     33.8 : 1.0\n",
            "                     x15 = True           Negati : Positi =     17.3 : 1.0\n",
            "               community = True           Positi : Negati =     16.0 : 1.0\n",
            "                      aw = True           Negati : Positi =     12.7 : 1.0\n",
            "                   didnt = True           Negati : Positi =     11.4 : 1.0\n",
            "                    glad = True           Positi : Negati =     11.3 : 1.0\n",
            "               goodnight = True           Positi : Negati =     10.6 : 1.0\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that the model is 99.6% accurate which is great! We also see which words are most associated with positive or negative sentiment. A smiley face most often means a tweet is positive, whereas if the tweet contains a sad face there's a good chance the tweet is negative."
      ],
      "metadata": {
        "id": "rPEU_ypMiKU-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running for GOT data"
      ],
      "metadata": {
        "id": "GR95TdvEHbBV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After setting up the classifier model, we will clean our *Game of Thrones* tweets and then run the classifier on them to determine the sentiment."
      ],
      "metadata": {
        "id": "pg0xkHdWjYae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the dataframe to a list\n",
        "got_text = gotsa['text'].to_numpy()"
      ],
      "metadata": {
        "id": "wmLOsZpJWK7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the tweet tokenizer\n",
        "tweet_tokenizer = TweetTokenizer()\n",
        "\n",
        "got_tokens = []\n",
        "\n",
        "# Tokenize the tweets\n",
        "for sent in got_text:\n",
        "  got_tokens.append(tweet_tokenizer.tokenize(sent))"
      ],
      "metadata": {
        "id": "IYFPNUszGyWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the tweets are tokenized, we will clean them up the same way we did with the twitter samples."
      ],
      "metadata": {
        "id": "8d6QrUBJkZOp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_tokens = []\n",
        "for i in range(len(got_tokens)):\n",
        "  row_token = []\n",
        "  for token, tag in pos_tag(got_tokens[i]):\n",
        "    token = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+#]|[!*\\(\\),]|'\\\n",
        "                    '(?:%[0-9a-fA-F][0-9a-fA-F]))+','', token) # remove any hyperlinks\n",
        "    token = re.sub('(@[A-Za-z0-9_]+)','', token) # remove any twitter handles\n",
        "    if tag.startswith('NN'): # assigning nouns\n",
        "      pos = 'n'\n",
        "    elif tag.startswith('VB'): # assigning verbs\n",
        "      pos = 'v'\n",
        "    else: # assigning adjectives\n",
        "      pos = 'a'\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    token = lemmatizer.lemmatize(token, pos) # lemmatize the token\n",
        "    if len(token) > 0 and token not in string.punctuation and token.lower() not in stop_words:\n",
        "      row_token.append(token.lower()) # save the token to the row (tweet)\n",
        "  cleaned_tokens.append(row_token) # save the row (tweet) to the list of cleaned tweets"
      ],
      "metadata": {
        "id": "d2ceOWNjKWll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we run the *Game of Thrones* dataset through the classifier to get the sentiment for each tweet."
      ],
      "metadata": {
        "id": "aVXUDdlQlCJo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "got_sent = []\n",
        "for tokens in cleaned_tokens:\n",
        "  got_dict = dict([token, True] for token in tokens)\n",
        "  got_sent.append(classifier.classify(got_dict))"
      ],
      "metadata": {
        "id": "aifpRUmqnmq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's add the results to our dataframe and we can see each tweet and it's sentiment."
      ],
      "metadata": {
        "id": "WcrO74x_lOxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gotsa['sentiment'] = got_sent\n",
        "gotsa.head()"
      ],
      "metadata": {
        "id": "plp11VNVv_g0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "outputId": "0167f7bb-f4e3-425c-b955-f37fb134c328"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            created_at                                               text  \\\n",
              "0  2019-04-17 07:34:18  üëç on @YouTube: GAME OF THRONES 8x01 Breakdown!...   \n",
              "1  2019-04-16 03:34:16  üëç on @YouTube: Ups and Downs From Game Of Thro...   \n",
              "2  2019-04-16 03:06:08  Liked on YouTube: Ups and Downs From Game Of T...   \n",
              "3  2019-04-17 07:07:38  Liked on YouTube: GAME OF THRONES 8x01 Breakdo...   \n",
              "4  2019-04-17 07:34:09  @MrLegenDarius unpopular opinion: game of thro...   \n",
              "\n",
              "  sentiment  \n",
              "0  Positive  \n",
              "1  Negative  \n",
              "2  Negative  \n",
              "3  Positive  \n",
              "4  Positive  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0bc31044-8504-45a3-a9f5-b07f0e4225a1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-04-17 07:34:18</td>\n",
              "      <td>üëç on @YouTube: GAME OF THRONES 8x01 Breakdown!...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019-04-16 03:34:16</td>\n",
              "      <td>üëç on @YouTube: Ups and Downs From Game Of Thro...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-04-16 03:06:08</td>\n",
              "      <td>Liked on YouTube: Ups and Downs From Game Of T...</td>\n",
              "      <td>Negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019-04-17 07:07:38</td>\n",
              "      <td>Liked on YouTube: GAME OF THRONES 8x01 Breakdo...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-04-17 07:34:09</td>\n",
              "      <td>@MrLegenDarius unpopular opinion: game of thro...</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0bc31044-8504-45a3-a9f5-b07f0e4225a1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0bc31044-8504-45a3-a9f5-b07f0e4225a1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0bc31044-8504-45a3-a9f5-b07f0e4225a1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before saving the dataset, let's get an idea of the percentages of positive and negative tweets there were."
      ],
      "metadata": {
        "id": "0ois5i6LlarL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gotsa['sentiment'].value_counts(normalize=True)"
      ],
      "metadata": {
        "id": "2UO16KjIt3GO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4003203-7cb3-4b97-9fa3-a0cd4814b474"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Negative    0.590307\n",
              "Positive    0.409693\n",
              "Name: sentiment, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Almost 60% of the tweets were negative! However, for a better representation of sentiment in the future, we should create our own rules on what is defined as positive and negative. But in this notebook, we used a sample dataset that contains sentiment already to train the model. In the following notebook, we will see how the sentiment changed over time. "
      ],
      "metadata": {
        "id": "t3Gp8uc5lsB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the dataset\n",
        "gotsa.to_csv('/content/drive/MyDrive/got_sa.csv', index=False)"
      ],
      "metadata": {
        "id": "TCajM9WAt_VW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}